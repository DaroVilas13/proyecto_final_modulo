{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b956324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import batch_normalization\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.activation import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e61c7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_02 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_03 62\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_04 213\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_05 105\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_06 949\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_07 37\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1633\n",
      "leyendo imagenes de  c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_01 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_02 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_03 48\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_04 97\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_05 45\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_06 459\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_07 19\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_08 114\n",
      "Directorios leidos: 8\n",
      "Imagenes en cada directorio [2, 48, 97, 45, 459, 19, 114, 26]\n",
      "suma Total de imagenes en subdirs: 810\n"
     ]
    }
   ],
   "source": [
    "dirname_train = os.path.join(os.getcwd(), 'train')\n",
    "imgpath_train = dirname_train + os.sep \n",
    "\n",
    "images_train = []\n",
    "directories_train = []\n",
    "dircount_train = []\n",
    "prevRoot_train=''\n",
    "cant_train=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath_train)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath_train):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant_train=cant_train+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images_train.append(image)\n",
    "            b = \"Leyendo...\" + str(cant_train)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant_train)\n",
    "                prevRoot=root\n",
    "                directories_train.append(root)\n",
    "                dircount_train.append(cant_train)\n",
    "                cant_train=0\n",
    "dircount_train.append(cant_train)\n",
    "\n",
    "dircount = dircount_train[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories_train))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))\n",
    "\n",
    "dirname_test = os.path.join(os.getcwd(), 'test')\n",
    "imgpath_test = dirname_test + os.sep \n",
    "\n",
    "images_test = []\n",
    "directories_test = []\n",
    "dircount_test = []\n",
    "prevRoot_test=''\n",
    "cant_test=0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath_test)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath_test):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant_test=cant_test+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images_test.append(image)\n",
    "            b = \"Leyendo...\" + str(cant_test)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot !=root:\n",
    "                print(root, cant_test)\n",
    "                prevRoot=root\n",
    "                directories_test.append(root)\n",
    "                dircount_test.append(cant_test)\n",
    "                cant_test=0\n",
    "dircount_test.append(cant_test)\n",
    "\n",
    "dircount = dircount_test[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories_test))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4b31564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Total number of outputs :  8\n",
      "Output classes :  [0 1 2 3 4 5 6 7]\n",
      "Cantidad etiquetas creadas:  810\n",
      "0 CLASS_01\n",
      "1 CLASS_02\n",
      "2 CLASS_03\n",
      "3 CLASS_04\n",
      "4 CLASS_05\n",
      "5 CLASS_06\n",
      "6 CLASS_07\n",
      "7 CLASS_08\n",
      "Total number of outputs :  9\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "labels_train=[]\n",
    "indice_train=0\n",
    "for cantidad in dircount_train:\n",
    "    for i in range(cantidad):\n",
    "        labels_train.append(indice_train)\n",
    "    indice_train=indice_train+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels_train))\n",
    "\n",
    "clases_carne_train=[]\n",
    "indice_train=0\n",
    "for directorio in directories_train:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice_train , name[len(name)-1])\n",
    "    clases_carne_train.append(name[len(name)-1])\n",
    "    indice_train=indice_train+1\n",
    "\n",
    "y_train = np.array(labels_train)\n",
    "X_train = np.array(images_train, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes_train = np.unique(y_train)\n",
    "nClasses_train = len(classes_train)\n",
    "print('Total number of outputs : ', nClasses_train)\n",
    "print('Output classes : ', classes_train)\n",
    "\n",
    "##########\n",
    "\n",
    "labels_test=[]\n",
    "indice_test=0\n",
    "for cantidad in dircount_test:\n",
    "    for i in range(cantidad):\n",
    "        labels_test.append(indice_test)\n",
    "    indice_test=indice_test+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels_test))\n",
    "\n",
    "clases_carne_test=[]\n",
    "indice_test=0\n",
    "for directorio in directories_test:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice_test , name[len(name)-1])\n",
    "    clases_carne_test.append(name[len(name)-1])\n",
    "    indice_test=indice_test+1\n",
    "\n",
    "y_test = np.array(labels_test)\n",
    "X_test = np.array(images_test, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes_test = np.unique(y_test)\n",
    "nClasses_test = len(classes_test)\n",
    "print('Total number of outputs : ', nClasses_test)\n",
    "print('Output classes : ', classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3464e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1633, 216, 384, 3) (1633,)\n",
      "Testing data shape :  (810, 216, 384, 3) (810,)\n",
      "Original label: 0\n",
      "After conversion to one-hot: [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(1224, 216, 384, 3) (409, 216, 384, 3) (1224, 8) (409, 8)\n"
     ]
    }
   ],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "#train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
    "train_X=X_train\n",
    "test_X=X_test\n",
    "train_Y=y_train\n",
    "test_Y=y_test\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
    " \n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    " \n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
    " \n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot)\n",
    " \n",
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dde797db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 384, 216, 32)      896       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 384, 216, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 192, 108, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 192, 108, 32)      0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 663552)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                21233696  \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,234,856\n",
      "Trainable params: 21,234,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\adagrad.py:84: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 6\n",
    "batch_size = 64\n",
    " \n",
    "carne_model = Sequential()\n",
    "carne_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(384,216,3)))\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "carne_model.add(Dropout(0.5))\n",
    " \n",
    "carne_model.add(Flatten())\n",
    "carne_model.add(Dense(32, activation='linear'))\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(Dropout(0.5)) \n",
    "carne_model.add(Dense(nClasses_train, activation='softmax'))\n",
    " \n",
    "carne_model.summary()\n",
    " \n",
    "carne_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b06ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 384, 216, 3), found shape=(None, 216, 384, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sport_train_dropout \u001b[39m=\u001b[39m carne_model\u001b[39m.\u001b[39;49mfit(train_X, train_label, batch_size\u001b[39m=\u001b[39;49mbatch_size,epochs\u001b[39m=\u001b[39;49mepochs,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m(valid_X, valid_label))\n\u001b[0;32m      3\u001b[0m \u001b[39m# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\u001b[39;00m\n\u001b[0;32m      4\u001b[0m carne_model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mcarnes_mnist.h5py\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filep8djvmm8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 384, 216, 3), found shape=(None, 216, 384, 3)\n"
     ]
    }
   ],
   "source": [
    "sport_train_dropout = carne_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "\n",
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "carne_model.save(\"carnes_mnist.h5py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "25aa516d811766120293c5dcb739461d5096634a1074b205c6c75447d7a41149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
