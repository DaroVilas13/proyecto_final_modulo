{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0b956324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import batch_normalization\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.activation import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e61c7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de entrenamiento:  c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_02 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_03 62\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_04 213\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_05 105\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_06 949\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_07 37\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1633\n",
      "leyendo imagenes de testeo:  c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_01 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_02 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_03 48\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_04 97\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_05 45\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_06 459\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_07 19\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_08 114\n",
      "Directorios leidos: 8\n",
      "Imagenes en cada directorio [2, 48, 97, 45, 459, 19, 114, 26]\n",
      "suma Total de imagenes en subdirs: 810\n"
     ]
    }
   ],
   "source": [
    "dirname_train = os.path.join(os.getcwd(), 'train')\n",
    "imgpath_train = dirname_train + os.sep \n",
    "\n",
    "images_train = []\n",
    "directories_train = []\n",
    "dircount_train = []\n",
    "prevRoot_train=''\n",
    "cant_train=0\n",
    "\n",
    "print(\"leyendo imagenes de entrenamiento: \",imgpath_train)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath_train):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant_train=cant_train+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images_train.append(image)\n",
    "            b = \"Leyendo...\" + str(cant_train)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot_train !=root:\n",
    "                print(root, cant_train)\n",
    "                prevRoot_train=root\n",
    "                directories_train.append(root)\n",
    "                dircount_train.append(cant_train)\n",
    "                cant_train=0\n",
    "dircount_train.append(cant_train)\n",
    "\n",
    "dircount = dircount_train[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories_train))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))\n",
    "\n",
    "dirname_test = os.path.join(os.getcwd(), 'test')\n",
    "imgpath_test = dirname_test + os.sep \n",
    "\n",
    "images_test = []\n",
    "directories_test = []\n",
    "dircount_test = []\n",
    "prevRoot_test=''\n",
    "cant_test=0\n",
    "\n",
    "print(\"leyendo imagenes de testeo: \",imgpath_test)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath_test):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant_test=cant_test+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images_test.append(image)\n",
    "            b = \"Leyendo...\" + str(cant_test)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot_test !=root:\n",
    "                print(root, cant_test)\n",
    "                prevRoot_test=root\n",
    "                directories_test.append(root)\n",
    "                dircount_test.append(cant_test)\n",
    "                cant_test=0\n",
    "dircount_test.append(cant_test)\n",
    "\n",
    "dircount = dircount_test[1:]\n",
    "dircount[0]=dircount[0]+1\n",
    "print('Directorios leidos:',len(directories_test))\n",
    "print(\"Imagenes en cada directorio\", dircount)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d4b31564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Total number of outputs :  8\n",
      "Output classes :  [0 1 2 3 4 5 6 7]\n",
      "Cantidad etiquetas creadas:  810\n",
      "0 CLASS_01\n",
      "1 CLASS_02\n",
      "2 CLASS_03\n",
      "3 CLASS_04\n",
      "4 CLASS_05\n",
      "5 CLASS_06\n",
      "6 CLASS_07\n",
      "7 CLASS_08\n",
      "Total number of outputs :  9\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "labels_train=[]\n",
    "indice_train=0\n",
    "for cantidad in dircount_train:\n",
    "    for i in range(cantidad):\n",
    "        labels_train.append(indice_train)\n",
    "    indice_train=indice_train+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels_train))\n",
    "\n",
    "clases_carne_train=[]\n",
    "indice_train=0\n",
    "for directorio in directories_train:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice_train , name[len(name)-1])\n",
    "    clases_carne_train.append(name[len(name)-1])\n",
    "    indice_train=indice_train+1\n",
    "\n",
    "y_train = np.array(labels_train)\n",
    "X_train = np.array(images_train, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes_train = np.unique(y_train)\n",
    "nClasses_train = len(classes_train)\n",
    "print('Total number of outputs : ', nClasses_train)\n",
    "print('Output classes : ', classes_train)\n",
    "\n",
    "##########\n",
    "\n",
    "labels_test=[]\n",
    "indice_test=0\n",
    "for cantidad in dircount_test:\n",
    "    for i in range(cantidad):\n",
    "        labels_test.append(indice_test)\n",
    "    indice_test=indice_test+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels_test))\n",
    "\n",
    "clases_carne_test=[]\n",
    "indice_test=0\n",
    "for directorio in directories_test:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice_test , name[len(name)-1])\n",
    "    clases_carne_test.append(name[len(name)-1])\n",
    "    indice_test=indice_test+1\n",
    "\n",
    "y_test = np.array(labels_test)\n",
    "X_test = np.array(images_test, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes_test = np.unique(y_test)\n",
    "nClasses_test = len(classes_test)\n",
    "print('Total number of outputs : ', nClasses_test)\n",
    "print('Output classes : ', classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3464e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1306, 216, 384, 3) (1306,)\n",
      "Testing data shape :  (327, 216, 384, 3) (327,)\n",
      "Original label 0: 4\n",
      "Original label 1: 4\n",
      "After conversion to one-hot 0: [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "After conversion to one-hot 1: [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "(914, 216, 384, 3) \n",
      " (1306, 216, 384, 3) \n",
      " (392, 216, 384, 3) \n",
      " (914, 8) \n",
      " (392, 8)\n"
     ]
    }
   ],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,train_test_X,train_Y,train_test_Y = train_test_split(X_train,y_train,test_size=0.2)\n",
    "#train_X=X_train\n",
    "#train_X1=X_train\n",
    "#test_X=X_test\n",
    "#train_Y=y_train\n",
    "#test_Y=y_test\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ',train_test_X.shape, train_test_Y.shape)\n",
    "#normlizamos los valores \n",
    "train_X = train_X.astype('float32')\n",
    "train_X1=train_X.astype('float32')\n",
    "train_test_X = train_test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "train_X1 = train_X / 255.\n",
    "train_test_X = train_test_X / 255.\n",
    " \n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "train_test_Y_one_hot = to_categorical(train_test_Y)\n",
    "#train_Y_one_hot = to_categorical(train_Y,nClasses_train) # calses train\n",
    "#train_test_Y_one_hot = to_categorical(train_test_Y,nClasses_test) # clases train -> \n",
    " \n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0:', train_Y[0])\n",
    "print('Original label 1:', train_Y[1])\n",
    "print('After conversion to one-hot 0:', train_Y_one_hot[0])\n",
    "print('After conversion to one-hot 1:', train_Y_one_hot[1])\n",
    " \n",
    "#train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot,test_size=0.001, random_state=13)\n",
    "train_X,train_valid_X,train_label,train_valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.3, random_state=13)\n",
    "#train_X=train_X\n",
    "#valid_X=test_X\n",
    "#train_label=train_Y_one_hot\n",
    "#valid_label=test_Y_one_hot  #valid_label=test_Y_one_hot cambio iguala las clases al entrenamiento\n",
    " \n",
    "print(train_X.shape,\"\\n\",train_X1.shape,\"\\n\",train_valid_X.shape,\"\\n\",train_label.shape,\"\\n\",train_valid_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dde797db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_111 (Conv2D)         (None, 216, 384, 32)      896       \n",
      "                                                                 \n",
      " leaky_re_lu_147 (LeakyReLU)  (None, 216, 384, 32)     0         \n",
      "                                                                 \n",
      " max_pooling2d_111 (MaxPooli  (None, 108, 192, 32)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 108, 192, 64)      18496     \n",
      "                                                                 \n",
      " leaky_re_lu_148 (LeakyReLU)  (None, 108, 192, 64)     0         \n",
      "                                                                 \n",
      " max_pooling2d_112 (MaxPooli  (None, 54, 96, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 54, 96, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_149 (LeakyReLU)  (None, 54, 96, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_113 (MaxPooli  (None, 27, 48, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 27, 48, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_150 (LeakyReLU)  (None, 27, 48, 256)      0         \n",
      "                                                                 \n",
      " max_pooling2d_114 (MaxPooli  (None, 14, 24, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 14, 24, 256)       590080    \n",
      "                                                                 \n",
      " leaky_re_lu_151 (LeakyReLU)  (None, 14, 24, 256)      0         \n",
      "                                                                 \n",
      " max_pooling2d_115 (MaxPooli  (None, 7, 12, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 7, 12, 256)        0         \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 21504)             0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 256)               5505280   \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_152 (LeakyReLU)  (None, 64)               0         \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,525,448\n",
      "Trainable params: 6,525,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vilas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\adagrad.py:84: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 6\n",
    "batch_size = 64\n",
    " \n",
    "carne_model = Sequential()\n",
    "carne_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(216,384,3))) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "#------------------------------------------\n",
    "carne_model.add(Conv2D(64, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "carne_model.add(Conv2D(128, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "carne_model.add(Conv2D(256, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "carne_model.add(Conv2D(256, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "#-----------------------------------------------------\n",
    "\n",
    "carne_model.add(Dropout(0.5))\n",
    "carne_model.add(Flatten())\n",
    "carne_model.add(Dense(256, activation='linear'))  #32 -> 256\n",
    "carne_model.add(Dense(128, activation='linear'))  #32 -> 256\n",
    "carne_model.add(Dense(64, activation='linear'))  #32 -> 256\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(Dropout(0.5)) \n",
    "carne_model.add(Dense(nClasses_train, activation='softmax'))  #nClasses_train\n",
    " \n",
    "carne_model.summary()\n",
    "\n",
    "carne_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy']) \n",
    "#carne_model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7b06ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "15/15 [==============================] - 97s 7s/step - loss: 2.0548 - accuracy: 0.5514 - val_loss: 2.0209 - val_accuracy: 0.6046\n",
      "Epoch 2/6\n",
      "15/15 [==============================] - 100s 7s/step - loss: 2.0030 - accuracy: 0.5832 - val_loss: 1.9678 - val_accuracy: 0.6046\n",
      "Epoch 3/6\n",
      "15/15 [==============================] - 103s 7s/step - loss: 1.9487 - accuracy: 0.5842 - val_loss: 1.9062 - val_accuracy: 0.6046\n",
      "Epoch 4/6\n",
      "15/15 [==============================] - 111s 7s/step - loss: 1.8910 - accuracy: 0.5821 - val_loss: 1.8303 - val_accuracy: 0.6046\n",
      "Epoch 5/6\n",
      "15/15 [==============================] - 114s 8s/step - loss: 1.8039 - accuracy: 0.5864 - val_loss: 1.7278 - val_accuracy: 0.6046\n",
      "Epoch 6/6\n",
      "15/15 [==============================] - 103s 7s/step - loss: 1.6953 - accuracy: 0.5864 - val_loss: 1.6027 - val_accuracy: 0.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    }
   ],
   "source": [
    "carne_train_dropout = carne_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(train_valid_X, train_valid_label))\n",
    "\n",
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "carne_model.save(\"carnes_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a0b98011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 580ms/step - loss: 1.6655 - accuracy: 0.5382\n",
      "Test loss: 1.6654561758041382\n",
      "Test accuracy: 0.538226306438446\n"
     ]
    }
   ],
   "source": [
    "test_eval = carne_model.evaluate(train_test_X, train_test_Y_one_hot, verbose=1)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9c969656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 54s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  48,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  97,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  45,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 459,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  19,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 114,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  26,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_eval = carne_train_dropout.  (test_X, test_Y_one_hot)\n",
    "#test_eval = carne_model.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "\n",
    "\n",
    "y_prediccion_test=carne_model.predict(test_X)#.round()\n",
    "\n",
    "confusion_matrix(test_Y_one_hot.argmax(axis=1),y_prediccion_test.argmax(axis=1))\n",
    "\n",
    "#y_evaluado  classes_test\n",
    "\n",
    "#test_eval=carne_model.evaluate(test_X,test_Y_one_hot)\n",
    "\n",
    "#print('Test loss:', test_eval[0])\n",
    "#print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fa25a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 54s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  62,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 213,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 105,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 949,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  37,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 204,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  62,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediccion_train=carne_model.predict(train_X1)#.round()\n",
    "\n",
    "confusion_matrix(train_Y_one_hot.argmax(axis=1),y_prediccion_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2af0e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y prediccion test:\n",
      " [[0.02502248 0.03621426 0.12508775 ... 0.03625148 0.12942144 0.03373645]\n",
      " [0.02503335 0.03622847 0.1250963  ... 0.03626423 0.12944363 0.03374896]\n",
      " [0.02504068 0.03623236 0.12509951 ... 0.03627035 0.12946244 0.03375624]\n",
      " ...\n",
      " [0.02503066 0.03622072 0.12510064 ... 0.0362618  0.12945348 0.03374704]\n",
      " [0.02502976 0.03622518 0.1250937  ... 0.0362615  0.12944365 0.03374545]\n",
      " [0.02504211 0.03623896 0.12510657 ... 0.03627365 0.12945141 0.03375817]]\n",
      "y prediccion train:\n",
      " [[0.02505264 0.03625036 0.12511942 ... 0.03628502 0.12946868 0.03377111]\n",
      " [0.02499633 0.03618985 0.12505661 ... 0.03622678 0.12940839 0.03371052]\n",
      " [0.02504598 0.03624405 0.12510774 ... 0.036279   0.1294533  0.03376528]\n",
      " ...\n",
      " [0.02504724 0.03624348 0.12510768 ... 0.03627792 0.12945884 0.03376423]\n",
      " [0.02503075 0.03622408 0.12508531 ... 0.03626057 0.1294274  0.03374603]\n",
      " [0.02503702 0.03622614 0.12509543 ... 0.03626595 0.12943958 0.03375003]]\n",
      "Y prueba:\n",
      " [0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "Y train one hot:\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y prediccion test:\\n\",y_prediccion_test)\n",
    "print(\"y prediccion train:\\n\",y_prediccion_train)\n",
    "print(\"Y prueba:\\n\",test_Y)\n",
    "print(\"Y train one hot:\\n\",train_Y_one_hot)\n",
    "\n",
    "\n",
    "#print(\"X prueba\",test_X)\n",
    "\n",
    "#print(\"Y entrenamiento one\",train_Y_one_hot)\n",
    "#print(\"Y test one\",test_Y_one_hot)\n",
    "\n",
    "#confusion_matrix(test_Y,y_prediccion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "25aa516d811766120293c5dcb739461d5096634a1074b205c6c75447d7a41149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
