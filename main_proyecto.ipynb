{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b956324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import batch_normalization\n",
    "from keras.layers.activation import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e61c7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de entrenamiento:  c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_02 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_03 62\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_04 213\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_05 105\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_06 949\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_07 37\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\train\\CLASS_08 204\n",
      "Directorios leidos: 7\n",
      "Imagenes en cada directorio [63, 213, 105, 949, 37, 204, 62]\n",
      "suma Total de imagenes en subdirs: 1633\n",
      "leyendo imagenes de testeo:  c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_01 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_02 1\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_03 48\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_04 97\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_05 45\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_06 459\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_07 19\n",
      "c:\\Users\\vilas\\Documents\\TRATAMIENTO_DATOS\\prueba_final_modulo\\proyecto_final_modulo\\test\\CLASS_08 114\n",
      "Directorios leidos: 8\n",
      "Imagenes en cada directorio [2, 48, 97, 45, 459, 19, 114, 26]\n",
      "suma Total de imagenes en subdirs: 810\n"
     ]
    }
   ],
   "source": [
    "dirname_train = os.path.join(os.getcwd(), 'train')\n",
    "imgpath_train = dirname_train + os.sep \n",
    "\n",
    "images_train = []\n",
    "directories_train = []\n",
    "dircount_train = []\n",
    "prevRoot_train=''\n",
    "cant_train=0\n",
    "\n",
    "print(\"leyendo imagenes de entrenamiento: \",imgpath_train)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath_train):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant_train=cant_train+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images_train.append(image)\n",
    "            b = \"Leyendo...\" + str(cant_train)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot_train !=root:\n",
    "                print(root, cant_train)\n",
    "                prevRoot_train=root\n",
    "                directories_train.append(root)\n",
    "                dircount_train.append(cant_train)\n",
    "                cant_train=0\n",
    "dircount_train.append(cant_train)\n",
    "\n",
    "dircount_train = dircount_train[1:]\n",
    "dircount_train[0]=dircount_train[0]+1\n",
    "print('Directorios leidos:',len(directories_train))\n",
    "print(\"Imagenes en cada directorio\", dircount_train)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount_train))\n",
    "\n",
    "dirname_test = os.path.join(os.getcwd(), 'test')\n",
    "imgpath_test = dirname_test + os.sep \n",
    "\n",
    "images_test = []\n",
    "directories_test = []\n",
    "dircount_test = []\n",
    "prevRoot_test=''\n",
    "cant_test=0\n",
    "\n",
    "print(\"leyendo imagenes de testeo: \",imgpath_test)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath_test):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            cant_test=cant_test+1\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            images_test.append(image)\n",
    "            b = \"Leyendo...\" + str(cant_test)\n",
    "            print (b, end=\"\\r\")\n",
    "            if prevRoot_test !=root:\n",
    "                print(root, cant_test)\n",
    "                prevRoot_test=root\n",
    "                directories_test.append(root)\n",
    "                dircount_test.append(cant_test)\n",
    "                cant_test=0\n",
    "dircount_test.append(cant_test)\n",
    "\n",
    "dircount_test = dircount_test[1:]\n",
    "dircount_test[0]=dircount_test[0]+1\n",
    "print('Directorios leidos:',len(directories_test))\n",
    "print(\"Imagenes en cada directorio\", dircount_test)\n",
    "print('suma Total de imagenes en subdirs:',sum(dircount_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4b31564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  1633\n",
      "0 CLASS_02\n",
      "1 CLASS_03\n",
      "2 CLASS_04\n",
      "3 CLASS_05\n",
      "4 CLASS_06\n",
      "5 CLASS_07\n",
      "6 CLASS_08\n",
      "Total number of outputs :  7\n",
      "Output classes :  [0 1 2 3 4 5 6]\n",
      "Cantidad etiquetas creadas:  810\n",
      "0 CLASS_01\n",
      "1 CLASS_02\n",
      "2 CLASS_03\n",
      "3 CLASS_04\n",
      "4 CLASS_05\n",
      "5 CLASS_06\n",
      "6 CLASS_07\n",
      "7 CLASS_08\n",
      "Total number of outputs :  8\n",
      "Output classes :  [0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "labels_train=[]\n",
    "indice_train=0\n",
    "for cantidad in dircount_train:\n",
    "    for i in range(cantidad):\n",
    "        labels_train.append(indice_train)\n",
    "    indice_train=indice_train+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels_train))\n",
    "\n",
    "clases_carne_train=[]\n",
    "indice_train=0\n",
    "for directorio in directories_train:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice_train , name[len(name)-1])\n",
    "    clases_carne_train.append(name[len(name)-1])\n",
    "    indice_train=indice_train+1\n",
    "\n",
    "y_train = np.array(labels_train)\n",
    "X_train = np.array(images_train, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes_train = np.unique(y_train)\n",
    "nClasses_train = len(classes_train)\n",
    "print('Total number of outputs : ', nClasses_train)\n",
    "print('Output classes : ', classes_train)\n",
    "\n",
    "##########\n",
    "\n",
    "labels_test=[]\n",
    "indice_test=0\n",
    "for cantidad in dircount_test:\n",
    "    for i in range(cantidad):\n",
    "        labels_test.append(indice_test)\n",
    "    indice_test=indice_test+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels_test))\n",
    "\n",
    "clases_carne_test=[]\n",
    "indice_test=0\n",
    "for directorio in directories_test:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice_test , name[len(name)-1])\n",
    "    clases_carne_test.append(name[len(name)-1])\n",
    "    indice_test=indice_test+1\n",
    "\n",
    "y_test = np.array(labels_test)\n",
    "X_test = np.array(images_test, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes_test = np.unique(y_test)\n",
    "nClasses_test = len(classes_test)\n",
    "print('Total number of outputs : ', nClasses_test)\n",
    "print('Output classes : ', classes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3464e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1306, 216, 384, 3) (1306,)\n",
      "Testing data shape :  (327, 216, 384, 3) (327,)\n",
      "Original label 0: 5\n",
      "Original label 1: 1\n",
      "After conversion to one-hot 0: [0. 0. 0. 0. 0. 1. 0.]\n",
      "After conversion to one-hot 1: [0. 1. 0. 0. 0. 0. 0.]\n",
      "(914, 216, 384, 3) \n",
      " (1306, 216, 384, 3) \n",
      " (392, 216, 384, 3) \n",
      " (914, 7) \n",
      " (392, 7)\n"
     ]
    }
   ],
   "source": [
    "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,train_test_X,train_Y,train_test_Y = train_test_split(X_train,y_train,test_size=0.2)\n",
    "\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ',train_test_X.shape, train_test_Y.shape)\n",
    "#normlizamos los valores \n",
    "train_X = train_X.astype('float32')\n",
    "train_X1=train_X.astype('float32')\n",
    "train_test_X = train_test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "train_X1 = train_X / 255.\n",
    "train_test_X = train_test_X / 255.\n",
    " \n",
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "train_test_Y_one_hot = to_categorical(train_test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0:', train_Y[0])\n",
    "print('Original label 1:', train_Y[1])\n",
    "print('After conversion to one-hot 0:', train_Y_one_hot[0])\n",
    "print('After conversion to one-hot 1:', train_Y_one_hot[1])\n",
    "\n",
    "#train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot,test_size=0.001, random_state=13)\n",
    "train_X,train_valid_X,train_label,train_valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.3, random_state=13)\n",
    "\n",
    "\n",
    "print(train_X.shape,\"\\n\",train_X1.shape,\"\\n\",train_valid_X.shape,\"\\n\",train_label.shape,\"\\n\",train_valid_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dde797db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 216, 384, 32)      896       \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 216, 384, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 108, 192, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 108, 192, 64)      18496     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 108, 192, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 54, 96, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 54, 96, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 54, 96, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 27, 48, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 27, 48, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 27, 48, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 24, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 24, 256)       590080    \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 14, 24, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 12, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 12, 256)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 21504)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               5505280   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,525,383\n",
      "Trainable params: 6,525,383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 6\n",
    "batch_size = 64\n",
    "carne_model = Sequential()\n",
    "carne_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(216,384,3))) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "#------------------------------------------\n",
    "carne_model.add(Conv2D(64, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "carne_model.add(Conv2D(128, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "carne_model.add(Conv2D(256, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "carne_model.add(Conv2D(256, kernel_size=(3, 3),activation='linear',padding='same')) ##32  384,216\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(MaxPooling2D((2, 2),padding='same')) # tamaño de la matriz de agrupacion\n",
    "#-----------------------------------------------------\n",
    "carne_model.add(Dropout(0.5))\n",
    "carne_model.add(Flatten())\n",
    "carne_model.add(Dense(256, activation='linear'))  #32 -> 256\n",
    "carne_model.add(Dense(128, activation='linear'))  #32 -> 256\n",
    "carne_model.add(Dense(64, activation='linear'))  #32 -> 256\n",
    "carne_model.add(LeakyReLU(alpha=0.1))\n",
    "carne_model.add(Dropout(0.5)) \n",
    "carne_model.add(Dense(nClasses_train, activation='softmax'))  #nClasses_train\n",
    "carne_model.summary()\n",
    "carne_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b06ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "15/15 [==============================] - 125s 8s/step - loss: 1.9290 - accuracy: 0.5394 - val_loss: 1.9086 - val_accuracy: 0.5689\n",
      "Epoch 2/6\n",
      "15/15 [==============================] - 116s 8s/step - loss: 1.8919 - accuracy: 0.5777 - val_loss: 1.8734 - val_accuracy: 0.5689\n",
      "Epoch 3/6\n",
      "15/15 [==============================] - 99s 7s/step - loss: 1.8588 - accuracy: 0.5678 - val_loss: 1.8364 - val_accuracy: 0.5689\n",
      "Epoch 4/6\n",
      "15/15 [==============================] - 99s 7s/step - loss: 1.8198 - accuracy: 0.5733 - val_loss: 1.7947 - val_accuracy: 0.5689\n",
      "Epoch 5/6\n",
      "15/15 [==============================] - 97s 7s/step - loss: 1.7702 - accuracy: 0.5722 - val_loss: 1.7434 - val_accuracy: 0.5689\n",
      "Epoch 6/6\n",
      "15/15 [==============================] - 95s 6s/step - loss: 1.7161 - accuracy: 0.5744 - val_loss: 1.6793 - val_accuracy: 0.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: carnes_mnist.h5py\\assets\n"
     ]
    }
   ],
   "source": [
    "carne_train_dropout = carne_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(train_valid_X, train_valid_label))\n",
    "\n",
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "carne_model.save(\"carnes_mnist.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0b98011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 12s 1s/step - loss: 1.6588 - accuracy: 0.5994\n",
      "Test loss: 1.6588343381881714\n",
      "Test accuracy: 0.5993883609771729\n"
     ]
    }
   ],
   "source": [
    "test_eval = carne_model.evaluate(train_test_X, train_test_Y_one_hot, verbose=1)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c969656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 32s 1s/step\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_prediccion_test\u001b[39m=\u001b[39mcarne_model\u001b[39m.\u001b[39mpredict(X_test)\u001b[39m#.round()\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_Y_one_hot \u001b[39m=\u001b[39m to_categorical(train_Y)\n\u001b[1;32m----> 3\u001b[0m confusion_matrix(train_Y\u001b[39m.\u001b[39;49margmax(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),y_prediccion_test\u001b[39m.\u001b[39margmax(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "y_prediccion_test=carne_model.predict(X_test)#.round()\n",
    "test_Y_one_hot = to_categorical(train_Y)\n",
    "confusion_matrix(train_Y.argmax(axis=1),y_prediccion_test.argmax(axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa25a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 52s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,  52,   0,   0,   0],\n",
       "       [  0,   0,   0, 174,   0,   0,   0],\n",
       "       [  0,   0,   0,  88,   0,   0,   0],\n",
       "       [  0,   0,   0, 753,   0,   0,   0],\n",
       "       [  0,   0,   0,  32,   0,   0,   0],\n",
       "       [  0,   0,   0, 159,   0,   0,   0],\n",
       "       [  0,   0,   0,  48,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prediccion_train=carne_model.predict(train_X1)#.round()\n",
    "\n",
    "confusion_matrix(train_Y_one_hot.argmax(axis=1),y_prediccion_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y prediccion test:\\n\",y_prediccion_test)\n",
    "print(\"y prediccion train:\\n\",y_prediccion_train)\n",
    "print(\"Y prueba:\\n\",test_Y)\n",
    "print(\"Y train one hot:\\n\",train_Y_one_hot)\n",
    "\n",
    "\n",
    "#print(\"X prueba\",test_X)\n",
    "\n",
    "#print(\"Y entrenamiento one\",train_Y_one_hot)\n",
    "#print(\"Y test one\",test_Y_one_hot)\n",
    "\n",
    "#confusion_matrix(test_Y,y_prediccion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "25aa516d811766120293c5dcb739461d5096634a1074b205c6c75447d7a41149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
